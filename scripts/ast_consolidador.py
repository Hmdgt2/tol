# ast_consolidador.py
import ast
import os
import astunparse
import re
from typing import Dict, List, Set, Optional

class ASTConsolidator:
    def __init__(self, target_module, source_module, base_staging_dir):
        self.base_staging_dir = base_staging_dir
        self.target_module_path = os.path.join(base_staging_dir, f"{target_module}.py")
        self.source_module_path = os.path.join(base_staging_dir, f"{source_module}.py")
        
        # üÜï REGISTRO DE DEPEND√äNCIAS ESPECIAIS
        self.dependencias_especiais = {
            'cupy': ['cupy_gpu_analysis', 'cupy_matrix_operations', 'cupy_linear_algebra'],
            'jax': ['jax_autodiff_analysis', 'jax_hamiltonian_dynamics'],
            'mpi4py': ['mpi_distributed_analysis'],
            'pyspark': ['spark_big_data_analysis'],
            'cmdstanpy': ['stan_bayesian_inference'],
            'flint': ['arb_arbitrary_precision_analysis'],
            'gmpy2': ['gmpy2_multiprecision_analysis'],
            'symengine': ['symengine_fast_symbolic'],
            'pymc3': ['pymc3_probabilistic_modeling', 'pymc3_gaussian_process'],
            'tensorflow_probability': ['tfp_bayesian_analysis'],
            'vaex': ['vaex_lazy_dataframe_analysis'],
            'modin': ['modin_parallel_dataframe'],
            'dask_ml': ['dask_ml_distributed_learning'],
            'networkit': ['networkit_large_scale_graphs'],
            'astropy': ['astropy_astronomical_analysis'],
            'biopython': ['biopython_sequence_analysis'],
        }
        
        # üÜï CATEGORIAS DE IMPORTS
        self.categorias_imports = {
            'computacao_gpu': ['cupy', 'cupyx'],
            'computacao_distribuida': ['mpi4py', 'pyspark', 'dask'],
            'matematica_simbolica': ['sympy', 'symengine'],
            'aprendizado_maquina': ['sklearn', 'tensorflow', 'torch'],
            'estatistica_avancada': ['pymc3', 'cmdstanpy', 'tensorflow_probability'],
            'big_data': ['vaex', 'modin', 'dask'],
            'analise_numerica': ['scipy', 'numpy', 'mpmath'],
            'visualizacao': ['matplotlib', 'seaborn', 'plotly'],
        }

    def _carregar_ast(self, filepath):
        """Carrega e retorna o AST de um ficheiro."""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                source_code = f.read()
                return ast.parse(source_code)
        except FileNotFoundError:
            return ast.Module(body=[], type_ignores=[])
        except Exception as e:
            print(f"‚ùå Erro ao carregar {filepath}: {e}")
            return None

    def _escrever_ast(self, filepath, tree):
        """Escreve o AST de volta para o ficheiro."""
        try:
            code = astunparse.unparse(tree)
            
            # üÜï FORMATA√á√ÉO AUTOM√ÅTICA DO C√ìDIGO
            code = self._formatar_codigo(code)
            
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(code)
            return True
        except Exception as e:
            print(f"‚ùå Erro ao escrever {filepath}: {e}")
            return False

    def _formatar_codigo(self, code):
        """Aplica formata√ß√£o b√°sica ao c√≥digo."""
        # Remove m√∫ltiplas linhas em branco
        code = re.sub(r'\n\s*\n\s*\n', '\n\n', code)
        
        # Garante 2 linhas em branco entre fun√ß√µes
        code = re.sub(r'(\n)(def )', r'\1\n\2', code)
        
        # Remove espa√ßos em branco desnecess√°rios no final das linhas
        code = '\n'.join(line.rstrip() for line in code.split('\n'))
        
        return code + '\n'  # Garante nova linha no final

    def _encontrar_e_extrair_funcao(self, tree, func_name):
        """Encontra e extrai uma fun√ß√£o do AST, removendo-a da √°rvore original."""
        funcao_a_mover = None
        novos_nodes = []
        
        for node in tree.body:
            if isinstance(node, ast.FunctionDef) and node.name == func_name:
                funcao_a_mover = node
            else:
                novos_nodes.append(node)
        
        if funcao_a_mover:
            tree.body = novos_nodes
        
        return funcao_a_mover

    def _funcao_existe_no_destino(self, tree, func_name):
        """Verifica se a fun√ß√£o j√° existe no m√≥dulo de destino."""
        for node in tree.body:
            if isinstance(node, ast.FunctionDef) and node.name == func_name:
                return True
        return False

    def _extrair_imports_da_funcao(self, func_node):
        """Extrai imports necess√°rios da fun√ß√£o."""
        imports_encontrados = set()
        
        # üÜï Analisa o corpo da fun√ß√£o para encontrar imports impl√≠citos
        for node in ast.walk(func_node):
            if isinstance(node, ast.Call):
                # Verifica chamadas de fun√ß√µes de bibliotecas espec√≠ficas
                if isinstance(node.func, ast.Attribute):
                    if isinstance(node.func.value, ast.Name):
                        module_name = node.func.value.id
                        if module_name in self.dependencias_especiais:
                            imports_encontrados.add(module_name)
        
        return list(imports_encontrados)

    def _analisar_dependencias_funcao(self, func_node, func_name):
        """Analisa depend√™ncias espec√≠ficas da fun√ß√£o."""
        dependencias = set()
        
        # üÜï Verifica depend√™ncias baseadas no nome da fun√ß√£o
        for lib, funcoes in self.dependencias_especiais.items():
            if func_name in funcoes:
                dependencias.add(lib)
                print(f"    üì¶ Depend√™ncia detectada: {lib} para {func_name}")
        
        # üÜï Analisa o c√≥digo da fun√ß√£o
        code = astunparse.unparse(func_node)
        
        # Padr√µes de detec√ß√£o de bibliotecas
        padroes_dependencias = {
            'cupy': [r'cupy\.', r'cupyx\.'],
            'jax': [r'jax\.', r'jnp\.'],
            'mpi4py': [r'mpi4py', r'MPI\.'],
            'pyspark': [r'pyspark', r'SparkContext'],
            'pymc3': [r'pymc3', r'pm\.'],
            'tensorflow': [r'tensorflow', r'tf\.'],
            'torch': [r'torch', r'nn\.'],
            'dask': [r'dask\.'],
            'vaex': [r'vaex\.'],
            'modin': [r'modin\.'],
        }
        
        for lib, padroes in padroes_dependencias.items():
            for padrao in padroes:
                if re.search(padrao, code):
                    dependencias.add(lib)
        
        return list(dependencias)

    def _gerar_header_categoria(self, categoria):
        """Gera header apropriado para cada categoria de fun√ß√µes."""
        headers = {
            'sistemas_dinamicos_avancados': '''
# ============================================================
# SISTEMAS DIN√ÇMICOS AVAN√áADOS
# ============================================================
# An√°lise de sistemas n√£o-lineares, caos e atratores
''',
            'computacao_avancada': '''
# ============================================================
# COMPUTA√á√ÉO AVAN√áADA
# ============================================================
# GPU, paralelismo, JIT e computa√ß√£o distribu√≠da
''',
            'matematica_simbolica': '''
# ============================================================
# MATEM√ÅTICA SIMB√ìLICA
# ============================================================
# √Ålgebra computacional e an√°lise simb√≥lica
''',
            'analise_quantica': '''
# ============================================================
# AN√ÅLISE QU√ÇNTICA
# ============================================================
# M√©todos inspirados em mec√¢nica qu√¢ntica
''',
            'teoria_caos': '''
# ============================================================
# TEORIA DO CAOS
# ============================================================
# Sistemas ca√≥ticos e expoentes de Lyapunov
''',
            'big_data_scaleout': '''
# ============================================================
# BIG DATA & SCALE-OUT
# ============================================================
# Processamento de dados em grande escala
''',
            'precisao_arbitraria': '''
# ============================================================
# PRECIS√ÉO ARBITR√ÅRIA
# ============================================================
# C√°lculos com precis√£o extrema (GMP/MPFR/Arb)
''',
        }
        
        return headers.get(categoria, '')

    def _adicionar_docstring_automatica(self, func_node, categoria):
        """Adiciona/atualiza docstring baseada na categoria."""
        docstring_template = self._obter_template_docstring(categoria)
        
        # Verifica se j√° existe docstring
        if (func_node.body and 
            isinstance(func_node.body[0], ast.Expr) and 
            isinstance(func_node.body[0].value, ast.Str)):
            # Docstring existe, adiciona categoria se n√£o estiver presente
            docstring_atual = func_node.body[0].value.s
            if 'üî¨' not in docstring_atual and 'üéØ' not in docstring_atual:
                nova_docstring = f'{docstring_atual}\n\n{docstring_template}'
                func_node.body[0].value.s = nova_docstring
        else:
            # Adiciona nova docstring
            nova_docstring = ast.Expr(value=ast.Str(s=docstring_template))
            func_node.body.insert(0, nova_docstring)

    def _obter_template_docstring(self, categoria):
        """Retorna template de docstring baseado na categoria."""
        templates = {
            'computacao_avancada': '''
üî¨ **Categoria**: Computa√ß√£o Avan√ßada
üéØ **Performance**: Otimizada para GPU/Paralelismo
‚ö° **Complexidade**: Alta

‚ö†Ô∏è **Requisitos**: Depend√™ncias especiais podem ser necess√°rias
''',
            'sistemas_dinamicos_avancados': '''
üî¨ **Categoria**: Sistemas Din√¢micos
üéØ **Aplica√ß√£o**: An√°lise de sistemas n√£o-lineares
üìà **M√©todo**: Baseado em teoria do caos

üå™Ô∏è **Sistema**: N√£o-linear/Din√¢mico
''',
            'precisao_arbitraria': '''
üî¨ **Categoria**: Precis√£o Arbitr√°ria  
üéØ **Precis√£o**: M√∫ltipla precis√£o/Arbitr√°ria
üìä **M√©todo**: C√°lculos exatos

üíé **Garantia**: Precis√£o num√©rica rigorosa
''',
            'big_data_scaleout': '''
üî¨ **Categoria**: Big Data
üéØ **Escala**: Processamento distribu√≠do
üìà **Performance**: Otimizada para grandes volumes

üèóÔ∏è **Arquitetura**: Scale-out/Distribu√≠da
''',
        }
        
        return templates.get(categoria, '''
üî¨ **Categoria**: Fun√ß√£o Anal√≠tica
üéØ **Prop√≥sito**: An√°lise de padr√µes matem√°ticos
''')

    def _organizar_imports(self, tree):
        """Organiza e categoriza imports no m√≥dulo."""
        imports = []
        outros_nodes = []
        
        for node in tree.body:
            if isinstance(node, (ast.Import, ast.ImportFrom)):
                imports.append(node)
            else:
                outros_nodes.append(node)
        
        if not imports:
            return tree
        
        # üÜï Categoriza imports
        imports_categorizados = self._categorizar_imports(imports)
        
        # Reconstr√≥i o AST com imports organizados
        tree.body = imports_categorizados + outros_nodes
        return tree

    def _categorizar_imports(self, imports):
        """Categoriza imports por tipo de biblioteca."""
        categorias = {}
        
        for imp in imports:
            categoria = self._classificar_import(imp)
            if categoria not in categorias:
                categorias[categoria] = []
            categorias[categoria].append(imp)
        
        # üÜï Adiciona headers entre categorias
        resultado = []
        ordem_categorias = [
            'bibliotecas_padrao',
            'computacao_cientifica', 
            'aprendizado_maquina',
            'computacao_avancada',
            'visualizacao',
            'outros'
        ]
        
        for cat in ordem_categorias:
            if cat in categorias and categorias[cat]:
                # Adiciona coment√°rio de categoria
                if cat != 'bibliotecas_padrao':
                    comentario = ast.Expr(value=ast.Str(s=f'# {cat.replace("_", " ").title()}'))
                    resultado.append(comentario)
                resultado.extend(categorias[cat])
                resultado.append(ast.Pass())  # Linha em branco
        
        return resultado

    def _classificar_import(self, imp_node):
        """Classifica um import em categoria."""
        bibliotecas_cientificas = {'numpy', 'scipy', 'pandas', 'sympy', 'mpmath'}
        bibliotecas_ml = {'sklearn', 'tensorflow', 'torch', 'keras'}
        bibliotecas_avancadas = {'cupy', 'jax', 'mpi4py', 'dask', 'pyspark'}
        bibliotecas_viz = {'matplotlib', 'seaborn', 'plotly', 'bokeh'}
        
        if isinstance(imp_node, ast.Import):
            for alias in imp_node.names:
                if alias.name in bibliotecas_avancadas:
                    return 'computacao_avancada'
                elif alias.name in bibliotecas_cientificas:
                    return 'computacao_cientifica'
                elif alias.name in bibliotecas_ml:
                    return 'aprendizado_maquina'
                elif alias.name in bibliotecas_viz:
                    return 'visualizacao'
                elif '.' not in alias.name and alias.name not in {'os', 'sys', 'math'}:
                    return 'bibliotecas_padrao'
        
        return 'outros'

    def mover_funcao(self, func_name, nome_padrao=None):
        """
        Move a fun√ß√£o func_name do m√≥dulo de origem para o m√≥dulo de destino
        dentro da √°rea de staging.
        """
        nome_final = nome_padrao or func_name
        
        print(f"  üîß Processando: '{func_name}' ‚Üí '{nome_final}'")
        
        source_tree = self._carregar_ast(self.source_module_path)
        target_tree = self._carregar_ast(self.target_module_path)
        
        if source_tree is None or target_tree is None:
            return False

        # Extrair fun√ß√£o da origem
        funcao_a_mover = self._encontrar_e_extrair_funcao(source_tree, func_name)
        if not funcao_a_mover:
            print(f"    ‚ö†Ô∏è Fun√ß√£o '{func_name}' n√£o encontrada em {os.path.basename(self.source_module_path)}")
            return False

        # üÜï ANALISAR DEPEND√äNCIAS DA FUN√á√ÉO
        dependencias = self._analisar_dependencias_funcao(funcao_a_mover, func_name)
        if dependencias:
            print(f"    üì¶ Depend√™ncias detectadas: {', '.join(dependencias)}")

        # Verificar se j√° existe no destino
        if self._funcao_existe_no_destino(target_tree, nome_final):
            print(f"    ‚ö†Ô∏è '{nome_final}' j√° existe no destino. Eliminando duplicado da origem.")
            return self._escrever_ast(self.source_module_path, source_tree)
        
        # üÜï ADICIONAR METADADOS √Ä FUN√á√ÉO
        categoria = os.path.basename(self.target_module_path).replace('.py', '')
        self._adicionar_docstring_automatica(funcao_a_mover, categoria)
        
        # Renomear e adicionar ao destino
        funcao_a_mover.name = nome_final
        target_tree.body.append(funcao_a_mover)

        # üÜï ORGANIZAR IMPORTS NO DESTINO
        target_tree = self._organizar_imports(target_tree)

        # Escrever ficheiros atualizados
        sucesso_origem = self._escrever_ast(self.source_module_path, source_tree)
        sucesso_destino = self._escrever_ast(self.target_module_path, target_tree)

        if sucesso_origem and sucesso_destino:
            print(f"    ‚úÖ Sucesso: Movida para {os.path.basename(self.target_module_path)}")
            if dependencias:
                print(f"    üìã Depend√™ncias: {', '.join(dependencias)}")
            return True
        else:
            print(f"    ‚ùå Falha ao escrever ficheiros")
            return False

    # üÜï M√âTODO PARA VALIDA√á√ÉO DE DEPEND√äNCIAS
    def validar_dependencias_modulo(self, modulo_path):
        """Valida se todas as depend√™ncias do m√≥dulo est√£o dispon√≠veis."""
        tree = self._carregar_ast(modulo_path)
        if not tree:
            return False
        
        dependencias_encontradas = set()
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.Import, ast.ImportFrom)):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        dependencias_encontradas.add(alias.name.split('.')[0])
                else:
                    dependencias_encontradas.add(node.module.split('.')[0])
        
        # Verifica disponibilidade
        dependencias_faltantes = []
        for dep in dependencias_encontradas:
            try:
                __import__(dep)
            except ImportError:
                if dep in self.dependencias_especiais:
                    dependencias_faltantes.append(dep)
        
        return dependencias_faltantes
